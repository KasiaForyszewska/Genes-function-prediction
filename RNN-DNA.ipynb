{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Genes function prediction - RNN. Dataset - 70 000 sequences of DNA**"
      ],
      "metadata": {
        "id": "kmJkUlV43QFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import string\n",
        "from torch.nn.functional import cross_entropy\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Tuple, Optional, List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, new_data, classes): #przerobiÄ‡ new_data\n",
        "        \n",
        "        self.new_data = new_data\n",
        "        self.classes = classes\n",
        "        \n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        return self.new_data[ind], self.classes[ind]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.classes)"
      ],
      "metadata": {
        "id": "qOflGxCK3NS7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WGCXxu3b1TLN"
      },
      "outputs": [],
      "source": [
        "f = open('dna_70k_balanced.txt', \"r\")\n",
        "data = f.read()\n",
        "f.close()\n",
        "\n",
        "elements = re.findall(\"([ATGC]+)\\t+(\\d+)\", data)\n",
        "\n",
        "sequences = [s for s, n in elements]\n",
        "classes = [n for s, n in elements]\n",
        "classes = [int(i) for i in classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5QDDKVmXUyxk"
      },
      "outputs": [],
      "source": [
        "def DNA_encoded(sequence):\n",
        "    code = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
        "    fit = [code[x] for x in sequence]\n",
        "    matrix = np.eye(4)[fit]\n",
        "    return torch.FloatTensor(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5-zDojpVU1fZ"
      },
      "outputs": [],
      "source": [
        "new_data = [DNA_encoded(sequence) for sequence in sequences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EMZEZHsdU3uB"
      },
      "outputs": [],
      "source": [
        "# split into train and test indices\n",
        "test_frac = 0.1\n",
        "n_test = int(test_frac * len(classes))\n",
        "test_ind = np.random.choice(len(classes), size=n_test, replace=False)\n",
        "train_ind = np.setdiff1d(np.arange(len(classes)), test_ind)\n",
        "\n",
        "classes = torch.tensor(classes) #classes = classes.clone().detach()?\n",
        "train_classes = classes[train_ind]\n",
        "\n",
        "# calculate weights for BalancedSampler\n",
        "uni, counts = np.unique(train_classes, return_counts=True)\n",
        "weight_per_class = len(classes) / counts\n",
        "weight = [weight_per_class[c] for c in train_classes]\n",
        "# preapre the sampler\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=weight, num_samples=len(weight)) \n",
        "\n",
        "train_dataset = ListDataset(new_data=[x for i, x in enumerate(new_data) if i in train_ind], classes=train_classes)\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=1, sampler=sampler)\n",
        "\n",
        "test_dataset = ListDataset(new_data=[x for i, x in enumerate(new_data) if i in test_ind], classes=classes[test_ind])\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RTYUI3FhU7mj"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 input_size: int,\n",
        "                 hidden_size: int, \n",
        "                 output_size: int):\n",
        "        \"\"\"\n",
        "        :param input_size: int\n",
        "            Dimensionality of the input vector\n",
        "        :param hidden_size: int\n",
        "            Dimensionality of the hidden space\n",
        "        :param output_size: int\n",
        "            Desired dimensionality of the output vector\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.input_to_hidden = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "        self.hidden_to_output = torch.nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    # for the sake of simplicity a single forward will process only a single timestamp \n",
        "    def forward(self, \n",
        "                input: torch.tensor, \n",
        "                hidden: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
        "        \"\"\"\n",
        "        :param input: torch.tensor \n",
        "            Input tesnor for a single observation at timestep t\n",
        "            shape [batch_size, input_size]\n",
        "        :param hidden: torch.tensor\n",
        "            Representation of the memory of the RNN from previous timestep\n",
        "            shape [batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        \n",
        "        combined = torch.cat([input, hidden], dim=1) \n",
        "        hidden = torch.tanh(self.input_to_hidden(combined))\n",
        "        output = self.hidden_to_output(hidden)\n",
        "        \n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns initial value for the hidden state\n",
        "        \"\"\"\n",
        "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K46MsA9VNDv",
        "outputId": "365f68e7-5ab0-4ee9-9118-4d4d07ebc7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Progress:  0% Loss: 1.950\n"
          ]
        }
      ],
      "source": [
        "# initialize network and optimizer\n",
        "rnn = RNN(4, 28, 7) #liczba liter, hidden, liczba klas\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.01)   \n",
        "\n",
        "epochs = 10\n",
        "\n",
        "# main loop\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    loss_buffer = []\n",
        "    \n",
        "    for i, (x, y) in enumerate(train_loader):  \n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # get initial hidden state\n",
        "        hidden = rnn.init_hidden(x.shape[0])\n",
        "        \n",
        "        # get output for the sample, remember that we treat it as a sequence\n",
        "        # so you need to iterate over the 2nd, time dimensiotn\n",
        "\n",
        "        seq_len = x.shape[1]\n",
        "        \n",
        "        for t in range(seq_len): \n",
        "            x_t = x[:, t]\n",
        "            output, hidden = rnn(input=x_t, hidden=hidden)\n",
        "        \n",
        "        loss = cross_entropy(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()  \n",
        "        \n",
        "        loss_buffer.append(loss.item())\n",
        "        \n",
        "        if i % 1000 == 1:\n",
        "            print(f\"Epoch: {epoch} Progress: {100 * i/len(train_loader):2.0f}% Loss: {np.mean(loss_buffer):.3f}\")\n",
        "            loss_buffer = []\n",
        "\n",
        "\n",
        "# evaluate on the test set\n",
        "with torch.no_grad():\n",
        "    ps = []\n",
        "    ys = []\n",
        "    correct = 0\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        ys.append(y.numpy())\n",
        "\n",
        "        hidden = rnn.init_hidden(x.shape[0])\n",
        "        seq_len = x.shape[1]\n",
        "        \n",
        "        for t in range(seq_len): \n",
        "            x_t = x[:, t]\n",
        "            output, hidden = rnn(input=x_t, hidden=hidden)\n",
        "\n",
        "        pred = output.argmax(dim=1)\n",
        "        ps.append(pred.cpu().numpy())\n",
        "    \n",
        "    ps = np.concatenate(ps, axis=0)\n",
        "    ys = np.concatenate(ys, axis=0)\n",
        "    f1 = f1_score(ys, ps, average='weighted')\n",
        "    \n",
        "    print(f\"Final F1 score: {f1:.2f}\")\n",
        "    assert f1 > 0.15, \"You should get over 0.15 f1 score, try changing some hyperparams!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gene_class = {'0': 'G protein coupled receptors', '1': 'Tyrosine Kinase', '2': 'Tyrosine Phosphatase', '3': 'Synthetase', '4': 'Synthase', '5':'Ion Chanel', '6': 'Transcription Factor'}"
      ],
      "metadata": {
        "id": "r4jgK3Ya6Pcy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39ChcKfVEaw7"
      },
      "outputs": [],
      "source": [
        "def predict(seq: str, rnn: RNN):\n",
        "    \"\"\"Prints the name and model's top 3 predictions with scores\"\"\"\n",
        "    hidden = rnn.init_hidden(1)\n",
        "\n",
        "    for sequence in new_data:\n",
        "      for tensor in sequence:\n",
        "        output, hidden = rnn(tensor.unsqueeze(1).transpose(0, 1), hidden)\n",
        "    \n",
        "    topk = output.topk(3)\n",
        "    \n",
        "    first = gene_class[int(topk.indices[0][0])]\n",
        "    second = gene_class[int(topk.indices[0][1])]\n",
        "    third = gene_class[int(topk.indices[0][2])]\n",
        "    \n",
        "    print(f\"    {first}: {topk.values[0][0]}\")\n",
        "    print(f\"    {second}: {topk.values[0][1]}\")\n",
        "    print(f\"    {third}: {topk.values[0][2]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}